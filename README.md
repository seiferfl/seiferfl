

### ğŸ‘‹ Hi, I'm Florentin

I'm fascinated by the interface between **neuroscience** and **artificial intelligence** â€” especially when it comes to understanding **how biological systems learn, remember, and reason**.

ğŸ”¬ **Current Interests**  
- Biological learning algorithms (and how they might differ from backpropagation)
- Working memory and sequence modeling
- Mechanistic interpretability of neural networks
- Science of Learning


ğŸš§ **Current Projects**  
- ğŸ¤ Collaborating with [@LeonardVetter](https://github.com/LeonardVetter) on a project implementing and dissecting toy models using mechanistic interpretability tools.
- ğŸ§  Building a repository of simple, biologically inspired models that can solve basic reasoning tasks â€” bridging intuition from neuroscience and ML.


ğŸŒ± **Currently Learning**


---

### ğŸ›  Tech & Tools I Use

<!-- Badges for aesthetic; feel free to customize -->
![Python](https://img.shields.io/badge/-Python-3776AB?style=flat&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![Jupyter](https://img.shields.io/badge/-Jupyter-F37626?style=flat&logo=jupyter&logoColor=white)
![LaTeX](https://img.shields.io/badge/-LaTeX-008080?style=flat&logo=latex&logoColor=white)
![VS Code](https://img.shields.io/badge/-VS%20Code-007ACC?style=flat&logo=visual-studio-code&logoColor=white)

---

### ğŸ“˜ Recent Questions Iâ€™ve Been Thinking About

> ğŸ§© What kind of internal representations enable flexible generalization in both brains and machines?  
> ğŸ” Can simple recurrent structures (like RNNs) model working memory as efficiently as cortical circuits - and how?  

---

### ğŸ“« Let's Connect

- ğŸ”— [Twitter/X](https://x.com/DbgYBrn) | [LinkedIn](https://www.linkedin.com/in/florentin-seifert-50984233b/)


